============================================ 1 ==================================================

get_legals.py  : scrap html

formatter.py   : <p>.....</p> -> [{'เลขมาตรา': ['คำ', ...]}, {'เลขมาตรา': ['คำ', ...]}, ...]
                              -> law_with_words.pickle [ใช้ deepcut]
                              >> law_with_words.pickle

law_word_count.py   : count word in each law
                      [{'เลขมาตรา' : {'คำ': ความถี่, 'คำ': ความถี่, ...}},
                       {'เลขมาตรา' : {'คำ': ความถี่, 'คำ': ความถี่, ...}},
                       {...}] >> law_words_count.pickle

============================================= 2 =================================================

tf_generator.py     : เอาความถี่ ไปหารความยาวของแต่ละมาตรา >> law_words_tf.pickle
idf_generator.py    : เอาจำนวนมาตราทั้งหมด หารด้วยจำนวนคำที่มีมาตรานั้นๆ จะได้ idf ของคำๆ นั้น >> law_words_idf.pickle

============================================ NOTE ===============================================

*** ความถี่ต่ำมาก
    คำที่เกิดกับทุก doc

list คำที่ความถี่ต่ำออกมาก่อน
แบบแรกดู similarity





พูดหัวข้อ, scope, ทำไมถึงทำ

=========================================== PICKLE ==============================================

law_words_count.pickle  : [{'เลขมาตรา' : {'คำ': ความถี่, 'คำ': ความถี่, ...}},
                           {'เลขมาตรา' : {'คำ': ความถี่, 'คำ': ความถี่, ...}},
                           {...}]

law_with_words.pickle   : [{'เลขมาตรา': ['คำ', ...]}, {'เลขมาตรา': ['คำ', ...]}, ...]

law_words_idf.pickle    : {'คำ': idf, 'คำ': idf, ...}

law_words_tf.pickle     : [{'เลขมาตรา' : {'คำ': tf, 'คำ': tf, ...}},
                           {'เลขมาตรา' : {'คำ': tf, 'คำ': tf, ...}},
                           {...}]

============================================ BUG ================================================

file ที่ตัดแยกมาตรามา จำนวนมันไม่ถูกอ่ะ ยังไม่ได้เช็คด้วยมือ
