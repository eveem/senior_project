============================================ 1 ==================================================

get_legals.py  : scrap html

formatter.py   : <p>.....</p> -> [{'เลขมาตรา': ['คำ', ...]}, {'เลขมาตรา': ['คำ', ...]}, ...]
                              -> law_with_words.pickle [ใช้ deepcut]

law_word_count.py   : count word in each law
                      [{'เลขมาตรา' : {'คำ': ความถี่, 'คำ': ความถี่, ...}},
                       {'เลขมาตรา' : {'คำ': ความถี่, 'คำ': ความถี่, ...}},
                       {...}]

============================================= 2 =================================================

tf_generator.py     : เอาความถี่ ไปหารความยาวของแต่ละมาตรา
idf_generator.py    : เอาจำนวนมาตราทั้งหมด หารด้วยจำนวนคำที่มีมาตรานั้นๆ จะได้ idf ของคำๆ นั้น

count_law_per_word.py   :   ('คำ', จำนวนมาตราที่คำนี้ปรากฏ), ('คำ', จำนวนมาตราที่คำนี้ปรากฏ), ...

============================================ NOTE ===============================================

*** ความถี่ต่ำมาก
    คำที่เกิดกับทุก doc

list คำที่ความถี่ต่ำออกมาก่อน
แบบแรกดู similarity





พูดหัวข้อ, scope, ทำไมถึงทำ

=========================================== PICKLE ==============================================

law_words_count.pickle  :  [{'เลขมาตรา' : {'คำ': ความถี่, 'คำ': ความถี่, ...}},
                            {'เลขมาตรา' : {'คำ': ความถี่, 'คำ': ความถี่, ...}},
                            {...}]

law_with_words.pickle   :   [{'เลขมาตรา': ['คำ', ...]}, {'เลขมาตรา': ['คำ', ...]}, ...]

============================================ BUG ================================================

file ที่ตัดแยกมาตรามา จำนวนมันไม่ถูกอ่ะ ยังไม่ได้เช็คด้วยมือ
